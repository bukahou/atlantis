{
  "slug": "kafka",
  "meta": {
    "title": "Kafka",
    "description": "Apache Kafka 分布式消息流平台、生产消费模式与流处理",
    "order": 1,
    "tags": [
      "mq",
      "kafka",
      "streaming",
      "distributed"
    ]
  },
  "content": "<h1>Apache Kafka</h1>\n<h2>Kafka 概述</h2>\n<p>Kafka 是分布式流处理平台，提供高吞吐、低延迟的消息发布订阅和流处理能力。</p>\n<pre><code>Kafka 架构\n├── Producer - 消息生产者\n├── Consumer - 消息消费者\n├── Broker - 消息服务器\n├── Topic - 消息主题\n├── Partition - 分区 (并行单元)\n├── Consumer Group - 消费者组\n└── ZooKeeper/KRaft - 集群协调\n</code></pre>\n<h2>核心概念</h2>\n<h3>Topic 与 Partition</h3>\n<pre><code>Topic: user-events\n├── Partition 0: [msg1, msg4, msg7, ...]\n├── Partition 1: [msg2, msg5, msg8, ...]\n└── Partition 2: [msg3, msg6, msg9, ...]\n\n特点\n├── Partition 内消息有序\n├── 跨 Partition 无序\n├── 每条消息有唯一 Offset\n└── 支持数据保留策略\n</code></pre>\n<h3>副本机制</h3>\n<pre><code>Partition 副本\n├── Leader - 处理读写请求\n├── Follower - 同步 Leader 数据\n└── ISR - 同步副本集合\n\n配置\n├── replication.factor=3\n├── min.insync.replicas=2\n└── acks=all\n</code></pre>\n<h2>生产者</h2>\n<h3>Go 生产者</h3>\n<pre><code class=\"language-go\">import \"github.com/segmentio/kafka-go\"\n\n// 创建 Writer\nwriter := &#x26;kafka.Writer{\n    Addr:     kafka.TCP(\"localhost:9092\"),\n    Topic:    \"user-events\",\n    Balancer: &#x26;kafka.LeastBytes{},\n}\ndefer writer.Close()\n\n// 发送消息\nerr := writer.WriteMessages(context.Background(),\n    kafka.Message{\n        Key:   []byte(\"user-123\"),\n        Value: []byte(`{\"event\":\"login\",\"user\":\"123\"}`),\n        Headers: []kafka.Header{\n            {Key: \"type\", Value: []byte(\"login\")},\n        },\n    },\n)\n\n// 批量发送\nmessages := []kafka.Message{\n    {Key: []byte(\"key1\"), Value: []byte(\"value1\")},\n    {Key: []byte(\"key2\"), Value: []byte(\"value2\")},\n}\nerr = writer.WriteMessages(context.Background(), messages...)\n</code></pre>\n<h3>分区策略</h3>\n<pre><code class=\"language-go\">// 自定义分区器\ntype UserPartitioner struct {\n    partitions int\n}\n\nfunc (p *UserPartitioner) Balance(msg kafka.Message, partitions ...int) int {\n    // 按用户 ID 分区，保证同一用户消息顺序\n    userID := string(msg.Key)\n    hash := fnv.New32a()\n    hash.Write([]byte(userID))\n    return int(hash.Sum32()) % len(partitions)\n}\n\n// 使用\nwriter := &#x26;kafka.Writer{\n    Addr:     kafka.TCP(\"localhost:9092\"),\n    Topic:    \"user-events\",\n    Balancer: &#x26;UserPartitioner{},\n}\n</code></pre>\n<h2>消费者</h2>\n<h3>Go 消费者</h3>\n<pre><code class=\"language-go\">// 创建 Reader\nreader := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:   []string{\"localhost:9092\"},\n    Topic:     \"user-events\",\n    GroupID:   \"my-consumer-group\",\n    Partition: 0,\n    MinBytes:  10e3, // 10KB\n    MaxBytes:  10e6, // 10MB\n})\ndefer reader.Close()\n\n// 消费消息\nfor {\n    msg, err := reader.ReadMessage(context.Background())\n    if err != nil {\n        break\n    }\n    fmt.Printf(\"Offset: %d, Key: %s, Value: %s\\n\",\n        msg.Offset, msg.Key, msg.Value)\n}\n</code></pre>\n<h3>消费者组</h3>\n<pre><code class=\"language-go\">// 消费者组配置\nreader := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:        []string{\"localhost:9092\"},\n    GroupID:        \"order-processor\",\n    GroupTopics:    []string{\"orders\", \"payments\"},\n    StartOffset:    kafka.FirstOffset,\n    CommitInterval: time.Second,\n})\n\n// 手动提交 Offset\nfor {\n    msg, _ := reader.FetchMessage(context.Background())\n\n    // 处理消息\n    processMessage(msg)\n\n    // 提交 Offset\n    reader.CommitMessages(context.Background(), msg)\n}\n</code></pre>\n<h2>消息可靠性</h2>\n<h3>生产者确认</h3>\n<pre><code class=\"language-go\">// acks 配置\nwriter := &#x26;kafka.Writer{\n    Addr:         kafka.TCP(\"localhost:9092\"),\n    Topic:        \"critical-events\",\n    RequiredAcks: kafka.RequireAll, // 所有副本确认\n    Async:        false,            // 同步发送\n}\n\n// 重试配置\nwriter := &#x26;kafka.Writer{\n    Addr:       kafka.TCP(\"localhost:9092\"),\n    Topic:      \"events\",\n    MaxAttempts: 3,\n    BatchTimeout: 10 * time.Millisecond,\n}\n</code></pre>\n<h3>消费者保证</h3>\n<pre><code class=\"language-go\">// 精确一次语义 (Exactly Once)\n// 1. 幂等生产者\n// 2. 事务消费者\n// 3. 消费-处理-提交 原子性\n\nfunc processWithTransaction(reader *kafka.Reader) error {\n    msg, _ := reader.FetchMessage(context.Background())\n\n    // 开始数据库事务\n    tx, _ := db.Begin()\n\n    // 处理业务逻辑\n    err := processInTx(tx, msg)\n    if err != nil {\n        tx.Rollback()\n        return err\n    }\n\n    // 提交事务\n    tx.Commit()\n\n    // 提交 Offset\n    reader.CommitMessages(context.Background(), msg)\n    return nil\n}\n</code></pre>\n<h2>流处理</h2>\n<h3>Kafka Streams 概念</h3>\n<pre><code>流处理拓扑\n├── Source - 数据源\n├── Processor - 处理节点\n├── Sink - 输出\n└── State Store - 状态存储\n\n操作类型\n├── 无状态: map, filter, flatMap\n└── 有状态: aggregate, join, window\n</code></pre>\n<h3>Go 流处理</h3>\n<pre><code class=\"language-go\">// 简单流处理\nfunc streamProcess(reader *kafka.Reader, writer *kafka.Writer) {\n    for {\n        msg, _ := reader.ReadMessage(context.Background())\n\n        // 转换\n        transformed := transform(msg.Value)\n\n        // 过滤\n        if shouldKeep(transformed) {\n            // 输出到另一个 Topic\n            writer.WriteMessages(context.Background(),\n                kafka.Message{\n                    Key:   msg.Key,\n                    Value: transformed,\n                },\n            )\n        }\n    }\n}\n\n// 窗口聚合\ntype WindowAggregator struct {\n    window   time.Duration\n    buffer   map[string][]Message\n    lastFlush time.Time\n}\n\nfunc (w *WindowAggregator) Add(msg Message) {\n    key := string(msg.Key)\n    w.buffer[key] = append(w.buffer[key], msg)\n\n    if time.Since(w.lastFlush) > w.window {\n        w.flush()\n    }\n}\n</code></pre>\n<h2>监控指标</h2>\n<pre><code class=\"language-yaml\"># 关键指标\n生产者:\n  - record-send-rate      # 发送速率\n  - record-error-rate     # 错误率\n  - request-latency-avg   # 延迟\n\n消费者:\n  - records-consumed-rate # 消费速率\n  - records-lag          # 消费延迟\n  - commit-latency-avg   # 提交延迟\n\nBroker:\n  - bytes-in-per-sec     # 入站流量\n  - bytes-out-per-sec    # 出站流量\n  - under-replicated-partitions # 未同步分区\n</code></pre>\n<h2>总结</h2>\n<p>Kafka 要点：</p>\n<ol>\n<li><strong>架构</strong> - Topic、Partition、Consumer Group</li>\n<li><strong>可靠性</strong> - 副本、ACK、事务</li>\n<li><strong>性能</strong> - 批量、压缩、零拷贝</li>\n<li><strong>流处理</strong> - 无状态/有状态操作</li>\n<li><strong>监控</strong> - Lag、吞吐量、延迟</li>\n</ol>\n"
}