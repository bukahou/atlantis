{
  "slug": "kafka",
  "meta": {
    "title": "Kafka",
    "description": "Apache Kafka 分散メッセージストリーミングプラットフォーム、プロデューサー/コンシューマーとストリーム処理",
    "order": 1,
    "tags": [
      "mq",
      "kafka",
      "streaming",
      "distributed"
    ]
  },
  "content": "<h1>Apache Kafka</h1>\n<h2>Kafka 概要</h2>\n<p>Kafka は分散ストリーム処理プラットフォームで、高スループット、低レイテンシのメッセージパブリッシュ/サブスクライブとストリーム処理機能を提供します。</p>\n<pre><code>Kafka アーキテクチャ\n├── Producer - メッセージプロデューサー\n├── Consumer - メッセージコンシューマー\n├── Broker - メッセージサーバー\n├── Topic - メッセージトピック\n├── Partition - パーティション (並列単位)\n├── Consumer Group - コンシューマーグループ\n└── ZooKeeper/KRaft - クラスター調整\n</code></pre>\n<h2>コアコンセプト</h2>\n<h3>Topic と Partition</h3>\n<pre><code>Topic: user-events\n├── Partition 0: [msg1, msg4, msg7, ...]\n├── Partition 1: [msg2, msg5, msg8, ...]\n└── Partition 2: [msg3, msg6, msg9, ...]\n\n特徴\n├── Partition 内メッセージは順序保証\n├── 跨 Partition 順序なし\n├── 各メッセージは一意の Offset を持つ\n└── データ保持ポリシーサポート\n</code></pre>\n<h3>レプリケーション</h3>\n<pre><code>Partition レプリカ\n├── Leader - 読み書きリクエスト処理\n├── Follower - Leader データ同期\n└── ISR - 同期レプリカセット\n\n設定\n├── replication.factor=3\n├── min.insync.replicas=2\n└── acks=all\n</code></pre>\n<h2>プロデューサー</h2>\n<h3>Go プロデューサー</h3>\n<pre><code class=\"language-go\">import \"github.com/segmentio/kafka-go\"\n\n// Writer 作成\nwriter := &#x26;kafka.Writer{\n    Addr:     kafka.TCP(\"localhost:9092\"),\n    Topic:    \"user-events\",\n    Balancer: &#x26;kafka.LeastBytes{},\n}\ndefer writer.Close()\n\n// メッセージ送信\nerr := writer.WriteMessages(context.Background(),\n    kafka.Message{\n        Key:   []byte(\"user-123\"),\n        Value: []byte(`{\"event\":\"login\",\"user\":\"123\"}`),\n        Headers: []kafka.Header{\n            {Key: \"type\", Value: []byte(\"login\")},\n        },\n    },\n)\n\n// バッチ送信\nmessages := []kafka.Message{\n    {Key: []byte(\"key1\"), Value: []byte(\"value1\")},\n    {Key: []byte(\"key2\"), Value: []byte(\"value2\")},\n}\nerr = writer.WriteMessages(context.Background(), messages...)\n</code></pre>\n<h3>パーティション戦略</h3>\n<pre><code class=\"language-go\">// カスタムパーティショナー\ntype UserPartitioner struct {\n    partitions int\n}\n\nfunc (p *UserPartitioner) Balance(msg kafka.Message, partitions ...int) int {\n    // ユーザー ID でパーティション、同一ユーザーのメッセージ順序保証\n    userID := string(msg.Key)\n    hash := fnv.New32a()\n    hash.Write([]byte(userID))\n    return int(hash.Sum32()) % len(partitions)\n}\n\n// 使用\nwriter := &#x26;kafka.Writer{\n    Addr:     kafka.TCP(\"localhost:9092\"),\n    Topic:    \"user-events\",\n    Balancer: &#x26;UserPartitioner{},\n}\n</code></pre>\n<h2>コンシューマー</h2>\n<h3>Go コンシューマー</h3>\n<pre><code class=\"language-go\">// Reader 作成\nreader := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:   []string{\"localhost:9092\"},\n    Topic:     \"user-events\",\n    GroupID:   \"my-consumer-group\",\n    Partition: 0,\n    MinBytes:  10e3, // 10KB\n    MaxBytes:  10e6, // 10MB\n})\ndefer reader.Close()\n\n// メッセージ消費\nfor {\n    msg, err := reader.ReadMessage(context.Background())\n    if err != nil {\n        break\n    }\n    fmt.Printf(\"Offset: %d, Key: %s, Value: %s\\n\",\n        msg.Offset, msg.Key, msg.Value)\n}\n</code></pre>\n<h3>コンシューマーグループ</h3>\n<pre><code class=\"language-go\">// コンシューマーグループ設定\nreader := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:        []string{\"localhost:9092\"},\n    GroupID:        \"order-processor\",\n    GroupTopics:    []string{\"orders\", \"payments\"},\n    StartOffset:    kafka.FirstOffset,\n    CommitInterval: time.Second,\n})\n\n// 手動 Offset コミット\nfor {\n    msg, _ := reader.FetchMessage(context.Background())\n\n    // メッセージ処理\n    processMessage(msg)\n\n    // Offset コミット\n    reader.CommitMessages(context.Background(), msg)\n}\n</code></pre>\n<h2>メッセージ信頼性</h2>\n<h3>プロデューサー確認</h3>\n<pre><code class=\"language-go\">// acks 設定\nwriter := &#x26;kafka.Writer{\n    Addr:         kafka.TCP(\"localhost:9092\"),\n    Topic:        \"critical-events\",\n    RequiredAcks: kafka.RequireAll, // 全レプリカ確認\n    Async:        false,            // 同期送信\n}\n\n// リトライ設定\nwriter := &#x26;kafka.Writer{\n    Addr:       kafka.TCP(\"localhost:9092\"),\n    Topic:      \"events\",\n    MaxAttempts: 3,\n    BatchTimeout: 10 * time.Millisecond,\n}\n</code></pre>\n<h3>コンシューマー保証</h3>\n<pre><code class=\"language-go\">// Exactly Once セマンティクス\n// 1. 冪等プロデューサー\n// 2. トランザクションコンシューマー\n// 3. 消費-処理-コミット アトミック性\n\nfunc processWithTransaction(reader *kafka.Reader) error {\n    msg, _ := reader.FetchMessage(context.Background())\n\n    // データベーストランザクション開始\n    tx, _ := db.Begin()\n\n    // ビジネスロジック処理\n    err := processInTx(tx, msg)\n    if err != nil {\n        tx.Rollback()\n        return err\n    }\n\n    // トランザクションコミット\n    tx.Commit()\n\n    // Offset コミット\n    reader.CommitMessages(context.Background(), msg)\n    return nil\n}\n</code></pre>\n<h2>ストリーム処理</h2>\n<h3>Kafka Streams コンセプト</h3>\n<pre><code>ストリーム処理トポロジー\n├── Source - データソース\n├── Processor - 処理ノード\n├── Sink - 出力\n└── State Store - 状態ストア\n\n操作タイプ\n├── ステートレス: map, filter, flatMap\n└── ステートフル: aggregate, join, window\n</code></pre>\n<h3>Go ストリーム処理</h3>\n<pre><code class=\"language-go\">// シンプルストリーム処理\nfunc streamProcess(reader *kafka.Reader, writer *kafka.Writer) {\n    for {\n        msg, _ := reader.ReadMessage(context.Background())\n\n        // 変換\n        transformed := transform(msg.Value)\n\n        // フィルター\n        if shouldKeep(transformed) {\n            // 別の Topic に出力\n            writer.WriteMessages(context.Background(),\n                kafka.Message{\n                    Key:   msg.Key,\n                    Value: transformed,\n                },\n            )\n        }\n    }\n}\n\n// ウィンドウ集約\ntype WindowAggregator struct {\n    window   time.Duration\n    buffer   map[string][]Message\n    lastFlush time.Time\n}\n\nfunc (w *WindowAggregator) Add(msg Message) {\n    key := string(msg.Key)\n    w.buffer[key] = append(w.buffer[key], msg)\n\n    if time.Since(w.lastFlush) > w.window {\n        w.flush()\n    }\n}\n</code></pre>\n<h2>監視メトリクス</h2>\n<pre><code class=\"language-yaml\"># 主要メトリクス\nプロデューサー:\n  - record-send-rate      # 送信レート\n  - record-error-rate     # エラーレート\n  - request-latency-avg   # レイテンシ\n\nコンシューマー:\n  - records-consumed-rate # 消費レート\n  - records-lag          # 消費ラグ\n  - commit-latency-avg   # コミットレイテンシ\n\nBroker:\n  - bytes-in-per-sec     # インバウンドトラフィック\n  - bytes-out-per-sec    # アウトバウンドトラフィック\n  - under-replicated-partitions # 未同期パーティション\n</code></pre>\n<h2>まとめ</h2>\n<p>Kafka のポイント：</p>\n<ol>\n<li><strong>アーキテクチャ</strong> - Topic、Partition、Consumer Group</li>\n<li><strong>信頼性</strong> - レプリカ、ACK、トランザクション</li>\n<li><strong>パフォーマンス</strong> - バッチ、圧縮、ゼロコピー</li>\n<li><strong>ストリーム処理</strong> - ステートレス/ステートフル操作</li>\n<li><strong>監視</strong> - Lag、スループット、レイテンシ</li>\n</ol>\n"
}